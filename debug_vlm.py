#!/usr/bin/env python3
"""VLMéªŒè¯è°ƒè¯•è„šæœ¬"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent))

from src.models.model_loader import ModelLoader
from src.agents.vlm_agent import VLMAgent
from src.agents.query_processor import QueryProcessor
from src.utils.data_utils import load_yaml_config
import numpy as np

def debug_vlm_verification():
    """è°ƒè¯•VLMéªŒè¯è¿‡ç¨‹"""
    print("ğŸ” å¼€å§‹VLMéªŒè¯è°ƒè¯•...")
    
    # åŠ è½½é…ç½®
    data_config = load_yaml_config('configs/DOTA.yaml')
    class_names = list(data_config['names'].values())
    print(f"ğŸ“‹ DOTAç±»åˆ«: {class_names}")
    
    # åŠ è½½æ¨¡å‹
    model_loader = ModelLoader('configs/model_configs.yaml')
    yolo_model = model_loader.load_yolo(device='cuda')
    vlm_model = model_loader.load_vlm(device='cuda')
    
    # åˆ›å»ºVLM Agentï¼ˆä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼ï¼‰
    vlm_agent = VLMAgent(vlm_model, verification_threshold=0.1)  # é™ä½é˜ˆå€¼
    query_processor = QueryProcessor(class_names)
    
    # æµ‹è¯•å›¾åƒ
    image_path = 'data/DOTA/images/val/P0005.png'
    print(f"ğŸ–¼ï¸ æµ‹è¯•å›¾åƒ: {image_path}")
    
    # YOLOæ£€æµ‹
    print("\n1ï¸âƒ£ YOLOæ£€æµ‹...")
    detections = yolo_model.predict(image_path)
    print(f"   YOLOæ£€æµ‹åˆ° {len(detections['boxes'])} ä¸ªç›®æ ‡")
    
    if len(detections['boxes']) > 0:
        print(f"   å‰5ä¸ªæ£€æµ‹ç»“æœ:")
        for i in range(min(5, len(detections['boxes']))):
            print(f"     {detections['class_names'][i]}: {detections['scores'][i]:.3f}")
    
    # æµ‹è¯•ä¸åŒçš„VLMé˜ˆå€¼
    print("\n2ï¸âƒ£ æµ‹è¯•ä¸åŒVLMé˜ˆå€¼...")
    thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]
    
    for threshold in thresholds:
        vlm_agent_temp = VLMAgent(vlm_model, verification_threshold=threshold)
        verified_detections = vlm_agent_temp.verify_detections(image_path, detections)
        passed_count = len(verified_detections['boxes'])
        print(f"   é˜ˆå€¼ {threshold}: {passed_count}/{len(detections['boxes'])} é€šè¿‡éªŒè¯")
    
    # æµ‹è¯•CLIPç›¸ä¼¼åº¦åˆ†æ•°åˆ†å¸ƒ
    print("\n3ï¸âƒ£ åˆ†æCLIPç›¸ä¼¼åº¦åˆ†æ•°...")
    if len(detections['boxes']) > 0:
        # å–å‰10ä¸ªæ£€æµ‹è¿›è¡Œè¯¦ç»†åˆ†æ
        sample_detections = {
            'boxes': detections['boxes'][:10],
            'scores': detections['scores'][:10],
            'classes': detections['classes'][:10],
            'class_names': detections['class_names'][:10]
        }
        
        # æ‰‹åŠ¨è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        from PIL import Image
        image = Image.open(image_path)
        
        # è£å‰ªæ£€æµ‹æ¡†
        cropped_images = []
        for box in sample_detections['boxes']:
            x1, y1, x2, y2 = map(int, box)
            cropped = image.crop((x1, y1, x2, y2))
            cropped_images.append(cropped)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for i, (cropped_img, class_name) in enumerate(zip(cropped_images, sample_detections['class_names'])):
            query = f"a photo of a {class_name}"
            similarity = vlm_model.compute_similarity(cropped_img, query)[0, 0]
            similarities.append(similarity)
            print(f"   {class_name}: {similarity:.4f}")
        
        print(f"\nğŸ“Š ç›¸ä¼¼åº¦ç»Ÿè®¡:")
        print(f"   å¹³å‡: {np.mean(similarities):.4f}")
        print(f"   ä¸­ä½æ•°: {np.median(similarities):.4f}")
        print(f"   æœ€å°å€¼: {np.min(similarities):.4f}")
        print(f"   æœ€å¤§å€¼: {np.max(similarities):.4f}")
    
    # æ¨èé˜ˆå€¼
    print("\n4ï¸âƒ£ æ¨èè®¾ç½®...")
    print("   ğŸ’¡ å»ºè®®VLMéªŒè¯é˜ˆå€¼: 0.2-0.3")
    print("   ğŸ’¡ æˆ–è€…ç¦ç”¨VLMéªŒè¯è¿›è¡Œæµ‹è¯•")

if __name__ == "__main__":
    debug_vlm_verification()
